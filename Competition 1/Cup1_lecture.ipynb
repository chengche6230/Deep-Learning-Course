{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLab Cup 1: Text Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I know that Chill Wills usually played lovable...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The arrival of an world famous conductor sets ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This documentary is such a wonderful example o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I really tried to like this movie but in the e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not one of Monogram's better(not trying to be ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  I know that Chill Wills usually played lovable...          1\n",
       "1  The arrival of an world famous conductor sets ...          1\n",
       "2  This documentary is such a wonderful example o...          1\n",
       "3  I really tried to like this movie but in the e...          0\n",
       "4  Not one of Monogram's better(not trying to be ...          0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =pd.read_csv('./data/IMDB_datasets/train.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I know that Chill Wills usually played lovable old sorts in Westerns. But his role in this segment is something I've remembered for a long time. Wills could be a first rate villain. Yes, Burgess Meredith's Fall was correct! That look in Hepplewhite's eye! It expressed porcine greed, ignorance, and the threat of violence all at once. Quite a performance, I think.<br /><br />The segment itself was a good one, too. Question: couldn't the little black bag cure alcoholism? I guess it did, sort of, with Fall. But the doctor would have been wise to apply the cure, if he had it, as quickly as possible to Hepplewhite.<br /><br />There is one moment that was annoying but also necessary. And it is something that appears to recur in these Night Gallery segments. It's Serling's constant need to sermonize. For that's what we got, one more time, with Dr. Fall. I don't know what was more frustrating, losing the black bag and all its miracles or not being to stop Fall from preaching about the bag's benefit for humanity, all while rubbing Hepplewhite's greedy face in the mud, and, therefore, all but begging for Hepplewhite to strike out at him. But as I say, it was necessary. At least it was for me. Otherwise, we wouldn't have been able to see Wills' performance discussed above. All done without moving a muscle or speaking a word.\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[0, 'review'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, we clean up the text by:\n",
    "- removing all HTML tags\n",
    "- removing punctuation marks but emoticons\n",
    "- converting all characters to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def preprocessor(text):\n",
    "    # remove HTML tags\n",
    "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
    "    \n",
    "    # regex for matching emoticons, keep emoticons, ex: :), :-P, :-D\n",
    "    r = '(?::|;|=|X)(?:-)?(?:\\)|\\(|D|P)'\n",
    "    emoticons = re.findall(r, text)\n",
    "    text = re.sub(r, '', text)\n",
    "    \n",
    "    # convert to lowercase and append all emoticons behind (with space in between)\n",
    "    # replace('-','') removes nose of emoticons\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) + ' ' + ' '.join(emoticons).replace('-','')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['runners', 'like', 'running', 'and', 'thus', 'they', 'run']\n"
     ]
    }
   ],
   "source": [
    "def tokenizer(text):\n",
    "    return re.split('\\s+', text.strip())\n",
    "\n",
    "print(tokenizer('runners like running and thus they run'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['runner', 'like', 'run', 'and', 'thu', 'they', 'run']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "def tokenizer_stem(text):\n",
    "    porter = PorterStemmer()\n",
    "    return [porter.stem(word) for word in re.split('\\s+', text.strip())]\n",
    "\n",
    "print(tokenizer_stem('runners like running and thus they run'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop-Word Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['runner', 'like', 'run', 'thu', 'run']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Che\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "def tokenizer_stem_nostop(text):\n",
    "    porter = PorterStemmer()\n",
    "    return [porter.stem(w) for w in re.split('\\s+', text.strip()) \\\n",
    "            if w not in stop and re.match('[a-zA-Z]+', w)]\n",
    "\n",
    "print(tokenizer_stem_nostop('runners like running and thus they run'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BoW (Bag-of-Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[example documents]\n",
      "Study hard, then you will be happy and I will be happy\n",
      "\"I'm not happy :(\" \", because you don't study hard\n",
      "\n",
      "[vocabulary]\n",
      "{'studi': 2, 'hard': 1, 'happi': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Che\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "doc_dummy = [\"Study hard, then you will be happy and I will be happy\", \n",
    "           \"\\\"I'm not happy :(\\\" \\\", because you don't study hard\"]\n",
    "print('[example documents]\\n{}\\n'.format('\\n'.join(doc_dummy)))\n",
    "\n",
    "# ngram_range=(min,max), default: 1-gram => (1,1)\n",
    "count = CountVectorizer(ngram_range=(1, 1),\n",
    "                        preprocessor=preprocessor,\n",
    "                        tokenizer=tokenizer_stem_nostop)\n",
    "\n",
    "count.fit(doc_dummy)\n",
    "# dictionary is stored in vocabulary_\n",
    "BoW = count.vocabulary_\n",
    "print('[vocabulary]\\n{}'.format(BoW))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(did, vid)\ttf\n",
      "  (0, 0)\t2\n",
      "  (0, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 2)\t1\n",
      "\n",
      "Is document-term matrix a scipy.sparse matrix? True\n"
     ]
    }
   ],
   "source": [
    "# get matrix (doc_id, vocabulary_id) --> tf\n",
    "doc_bag = count.transform(doc_dummy)\n",
    "print('(did, vid)\\ttf')\n",
    "print(doc_bag)\n",
    "\n",
    "print('\\nIs document-term matrix a scipy.sparse matrix? {}'.format(sp.sparse.issparse(doc_bag)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 1 1]\n",
      " [1 1 1]]\n",
      "\n",
      "After calling .toarray(), is it a scipy.sparse matrix? False\n"
     ]
    }
   ],
   "source": [
    "doc_bag = doc_bag.toarray()\n",
    "print(doc_bag)\n",
    "\n",
    "print('\\nAfter calling .toarray(), is it a scipy.sparse matrix? {}'.format(sp.sparse.issparse(doc_bag)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[most frequent vocabularies]\n",
      "film: 230\n",
      "movi: 186\n",
      "one: 113\n",
      "like: 94\n",
      "make: 69\n",
      "good: 68\n",
      "see: 64\n",
      "watch: 59\n",
      "time: 55\n",
      "look: 55\n"
     ]
    }
   ],
   "source": [
    "doc = df['review'].iloc[:100]\n",
    "doc_bag = count.fit_transform(doc).toarray()\n",
    "\n",
    "print(\"[most frequent vocabularies]\")\n",
    "bag_cnts = np.sum(doc_bag, axis=0)\n",
    "top = 10\n",
    "# [::-1] reverses a list since sort is in ascending order\n",
    "for tok, v in zip(count.inverse_transform(np.ones(bag_cnts.shape[0]).reshape(1, -1))[0][bag_cnts.argsort()[::-1][:top]],\n",
    "                    np.sort(bag_cnts)[::-1][:top]):\n",
    "    print('{}: {}'.format(tok, v))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Che\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "C:\\Users\\Che\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[vocabularies with smallest idf scores]\n",
      "film: 1.31\n",
      "one: 1.47\n",
      "movi: 1.49\n",
      "like: 1.66\n",
      "good: 1.85\n",
      "see: 1.90\n",
      "make: 1.90\n",
      "time: 1.90\n",
      "look: 1.95\n",
      "realli: 2.00\n",
      "\n",
      "[vocabularies with highest tf-idf scores]\n",
      "film: 7.066901709415235\n",
      "movi: 6.299966884557826\n",
      "one: 3.4356531496083536\n",
      "like: 3.4259334935066805\n",
      "good: 3.0908848923824195\n",
      "watch: 2.9145931936069243\n",
      "see: 2.6096711446618777\n",
      "make: 2.533831399982588\n",
      "look: 2.303352832004743\n",
      "go: 2.2474055126830565\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,1),\n",
    "                        preprocessor=preprocessor,\n",
    "                        tokenizer=tokenizer_stem_nostop)\n",
    "\n",
    "tfidf.fit(doc)\n",
    "\n",
    "top = 10\n",
    "# get idf score of vocabularies\n",
    "idf = tfidf.idf_\n",
    "print('[vocabularies with smallest idf scores]')\n",
    "sorted_idx = idf.argsort()\n",
    "\n",
    "for i in range(top):\n",
    "    print('%s: %.2f' %(tfidf.get_feature_names()[sorted_idx[i]], idf[sorted_idx[i]]))\n",
    "\n",
    "doc_tfidf = tfidf.transform(doc).toarray()\n",
    "tfidf_sum = np.sum(doc_tfidf, axis=0)\n",
    "print(\"\\n[vocabularies with highest tf-idf scores]\")\n",
    "for tok, v in zip(tfidf.inverse_transform(np.ones(tfidf_sum.shape[0]).reshape(1, -1))[0][tfidf_sum.argsort()[::-1]][:top], \\\n",
    "                        np.sort(tfidf_sum)[::-1][:top]):\n",
    "    print('{}: {}'.format(tok, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3248)\n"
     ]
    }
   ],
   "source": [
    "print(doc_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Hashing\n",
    "* (+) no need to store vocabulary dictionary in memory anymore\n",
    "* (-) no way to map token index back to token via inverse_transform()\n",
    "* (-) no IDF weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[example documents]\n",
      "Study hard, then you will be happy and I will be happy\n",
      "\"I'm not happy :(\" \", because you don't study hard\n",
      "\n",
      "(2, 1024)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "print('[example documents]\\n{}\\n'.format('\\n'.join(doc_dummy)))\n",
    "\n",
    "# hash words to 1024 buckets\n",
    "hashvec = HashingVectorizer(n_features=2**10,\n",
    "                            preprocessor=preprocessor,\n",
    "                            tokenizer=tokenizer_stem_nostop)\n",
    "\n",
    "# no .fit needed for HashingVectorizer, since it's defined by the hash function\n",
    "\n",
    "# transform sentences to vectors of dimension 1024\n",
    "doc_hash = hashvec.transform(doc_dummy)\n",
    "print(doc_hash.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Classification Pipeline\n",
    "1. Preprocessing: clean the text, and remove stop words;\n",
    "2. Convert words to vector: extract feature vectors from the raw review text;\n",
    "3. Classification: train a LogisticRegression model to do sentiment classification;\n",
    "4. Evaluate: we'll do 10-fold cross-validation to evaluate general performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[auc (10-fold cv)]\n",
      "LogisticRegression: 0.881 (+/-0.042)\n",
      "LogisticRegression+(1,2)gram: 0.873 (+/-0.047)\n",
      "LogisticRegression+preprocess: 0.907 (+/-0.033)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Che\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "C:\\Users\\Che\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "C:\\Users\\Che\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "C:\\Users\\Che\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "C:\\Users\\Che\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "C:\\Users\\Che\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "C:\\Users\\Che\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "C:\\Users\\Che\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "C:\\Users\\Che\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "C:\\Users\\Che\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression+preprocess+hash: 0.855 (+/-0.039)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# randomly sample 1000 examples\n",
    "df_small = df.sample(n=1000, random_state=0)\n",
    "\n",
    "names = ['LogisticRegression', \n",
    "         'LogisticRegression+(1,2)gram',\n",
    "         'LogisticRegression+preprocess',\n",
    "         'LogisticRegression+preprocess+hash']\n",
    "# without preprocessing\n",
    "pipe1 = Pipeline([('vect', CountVectorizer()), \n",
    "                  ('clf', LogisticRegression(solver = \"liblinear\"))])\n",
    "# without preprocessing, use larger ngram range\n",
    "pipe2 = Pipeline([('vect', CountVectorizer(ngram_range=(1,3))), \n",
    "                  ('clf', LogisticRegression(solver = \"liblinear\"))])\n",
    "# with preprocessing\n",
    "pipe3 = Pipeline([('vect', TfidfVectorizer(preprocessor=preprocessor, \n",
    "                                           tokenizer=tokenizer_stem_nostop)), \n",
    "                  ('clf', LogisticRegression(solver = \"liblinear\"))])\n",
    "# with preprocessing and hasing\n",
    "pipe4 = Pipeline([('vect', HashingVectorizer(n_features=2**10,\n",
    "                                             preprocessor=preprocessor, \n",
    "                                             tokenizer=tokenizer_stem_nostop)), \n",
    "                  ('clf', LogisticRegression(solver = \"liblinear\"))])\n",
    "# CV\n",
    "print('[auc (10-fold cv)]')\n",
    "for name, clf in zip(names, [pipe1, pipe2, pipe3, pipe4]):\n",
    "    scores = cross_val_score(estimator=clf, X=df_small['review'], y=df_small['sentiment'], \\\n",
    "                         cv=10, scoring='roc_auc')\n",
    "    print('%s: %.3f (+/-%.3f)' % (name, scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More creative features\n",
    "Here are few examples for inspiration:\n",
    "\n",
    "* Weekday on which a news article get published: a news might be more popular if published on weekdays (or weekends);\n",
    "* Channel: sports channel might be more popular than financial channel;\n",
    "* Number of images/links: news might be more attractive if it contains more figures or links;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Out-of-Core Learning If You Don't Have Enough Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review  sentiment\n",
      "0  I know that Chill Wills usually played lovable...          1\n",
      "1  The arrival of an world famous conductor sets ...          1\n",
      "2  This documentary is such a wonderful example o...          1\n",
      "3  I really tried to like this movie but in the e...          0\n",
      "4  Not one of Monogram's better(not trying to be ...          0\n",
      "5  Don't get me wrong, I assumed this movie would...          0\n",
      "6  The `plot' of this film contains a few holes y...          0\n",
      "7  The best of the seven Sam Fuller movies that I...          1\n",
      "8  A gritty Australian film, with all the element...          1\n",
      "9  There are very few performers today who can ke...          1\n"
     ]
    }
   ],
   "source": [
    "def get_stream(path, size):\n",
    "    for chunk in pd.read_csv(path, chunksize=size):\n",
    "        yield chunk\n",
    "\n",
    "print(next(get_stream(path='./data/IMDB_datasets/train.csv', size=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2000/25000] 0.8781631566090401\n",
      "[4000/25000] 0.9016017025089605\n",
      "[6000/25000] 0.9005348540520527\n",
      "[8000/25000] 0.9104668103500175\n",
      "[10000/25000] 0.9169270833333333\n",
      "[12000/25000] 0.9210707371317941\n",
      "[14000/25000] 0.9426722756410256\n",
      "[16000/25000] 0.9417277669110675\n",
      "[18000/25000] 0.9396470343525497\n",
      "[20000/25000] 0.9287995198079232\n",
      "[22000/25000] 0.9406712473572938\n",
      "[24000/25000] 0.946104956454918\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "hashvec = HashingVectorizer(n_features=2**20, \n",
    "                            preprocessor=preprocessor, tokenizer=tokenizer_stem_nostop)\n",
    "# loss='log' gives logistic regression\n",
    "clf = SGDClassifier(loss='log', max_iter=100, tol=1e-3)\n",
    "batch_size = 1000\n",
    "stream = get_stream(path='./data/IMDB_datasets/train.csv', size=batch_size)\n",
    "classes = np.array([0, 1])\n",
    "train_auc, val_auc = [], []\n",
    "# we use one batch for training and another for validation in each iteration\n",
    "iters = int((25000+batch_size-1)/(batch_size*2))\n",
    "for i in range(iters):\n",
    "    batch = next(stream)\n",
    "    X_train, y_train = batch['review'], batch['sentiment']\n",
    "    if X_train is None:\n",
    "        break\n",
    "    X_train = hashvec.transform(X_train)\n",
    "    clf.partial_fit(X_train, y_train, classes=classes)\n",
    "    train_auc.append(roc_auc_score(y_train, clf.predict_proba(X_train)[:,1]))\n",
    "    \n",
    "    # validate\n",
    "    batch = next(stream)\n",
    "    X_val, y_val = batch['review'], batch['sentiment']\n",
    "    score = roc_auc_score(y_val, clf.predict_proba(hashvec.transform(X_val))[:,1])\n",
    "    val_auc.append(score)\n",
    "    print('[{}/{}] {}'.format((i+1)*(batch_size*2), 25000, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(1, len(train_auc)+1), train_auc, color='blue', label='Train auc')\n",
    "plt.plot(range(1, len(train_auc)+1), val_auc, color='red', label='Val auc')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel('#Batches')\n",
    "plt.ylabel('Auc')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./output/fig-out-of-core.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test auc: 0.931\n"
     ]
    }
   ],
   "source": [
    "# import optimized pickle written in C for serializing and \n",
    "# de-serializing a Python object\n",
    "import _pickle as pkl\n",
    "\n",
    "# dump to disk\n",
    "pkl.dump(hashvec, open('output/hashvec.pkl', 'wb'))\n",
    "pkl.dump(clf, open('output/clf-sgd.pkl', 'wb'))\n",
    "\n",
    "# load from disk\n",
    "hashvec = pkl.load(open('output/hashvec.pkl', 'rb'))\n",
    "clf = pkl.load(open('output/clf-sgd.pkl', 'rb'))\n",
    "\n",
    "df_test = pd.read_csv('./data/IMDB_datasets/test.csv')\n",
    "print('test auc: %.3f' % roc_auc_score(df_test['sentiment'], \\\n",
    "            clf.predict_proba(hashvec.transform(df_test['review']))[:,1]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "22c6df8416d99150f2220dbf1611e4fb62265fefa3bde7b85f317bcaabf8ed29"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
