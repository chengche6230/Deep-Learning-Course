{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq Learning & Neural Machine Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\" \n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pylab import *\n",
    "from matplotlib.font_manager import FontProperties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Restrict TensorFlow to only use the first GPU\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset path\n",
    "# use the Chinese-English dataset\n",
    "path_to_file = \"./dataset/eng-chinese.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "                   if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "\n",
    "def preprocess_eng(w):\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "\n",
    "    # creating a space between a word and the punctuation following it\n",
    "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "    # Reference:- https://stackoverflow.com/questions/3645931/\n",
    "    # python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "    w = re.sub(r\"([?.!,])\", r\" \\1 \", w)\n",
    "    # replace several spaces with one space\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", w)\n",
    "    w = w.rstrip().strip()\n",
    "\n",
    "    # adding a start and an end token to the sentence\n",
    "    # so that the model know when to start and stop predicting.\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w\n",
    "\n",
    "\n",
    "def preprocess_chinese(w):\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "    w = re.sub(r'[\" \"]+', \"\", w)\n",
    "    w = w.rstrip().strip()\n",
    "    w = \" \".join(list(w))  # add the space between words\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> may i borrow this book ? <end>\n",
      "<start> 我 可 以 借 這 本 書 麼 ？ <end>\n",
      "b'<start> \\xe6\\x88\\x91 \\xe5\\x8f\\xaf \\xe4\\xbb\\xa5 \\xe5\\x80\\x9f \\xe9\\x80\\x99 \\xe6\\x9c\\xac \\xe6\\x9b\\xb8 \\xe9\\xba\\xbc \\xef\\xbc\\x9f <end>'\n"
     ]
    }
   ],
   "source": [
    "# u means unicode encoder\n",
    "en_sentence = u\"May I borrow this book?\"\n",
    "chn_sentence = u\"我可以借這本書麼？\"\n",
    "print(preprocess_eng(en_sentence))\n",
    "print(preprocess_chinese(chn_sentence))\n",
    "print(preprocess_chinese(chn_sentence).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<start> hi . <end>', '<start> 嗨 。 <end>'],\n",
       " ['<start> hi . <end>', '<start> 你 好 。 <end>'],\n",
       " ['<start> run . <end>', '<start> 你 用 跑 的 。 <end>'],\n",
       " ['<start> wait ! <end>', '<start> 等 等 ！ <end>'],\n",
       " ['<start> hello ! <end>', '<start> 你 好 。 <end>'],\n",
       " ['<start> i try . <end>', '<start> 让 我 来 。 <end>'],\n",
       " ['<start> i won ! <end>', '<start> 我 赢 了 。 <end>'],\n",
       " ['<start> oh no ! <end>', '<start> 不 会 吧 。 <end>'],\n",
       " ['<start> cheers ! <end>', '<start> 乾 杯 ! <end>'],\n",
       " ['<start> he ran . <end>', '<start> 他 跑 了 。 <end>'],\n",
       " ['<start> hop in . <end>', '<start> 跳 进 来 。 <end>'],\n",
       " ['<start> i lost . <end>', '<start> 我 迷 失 了 。 <end>'],\n",
       " ['<start> i quit . <end>', '<start> 我 退 出 。 <end>'],\n",
       " ['<start> i m ok . <end>', '<start> 我 沒 事 。 <end>'],\n",
       " ['<start> listen . <end>', '<start> 听 着 。 <end>'],\n",
       " ['<start> no way ! <end>', '<start> 不 可 能 ！ <end>'],\n",
       " ['<start> no way ! <end>', '<start> 没 门 ！ <end>'],\n",
       " ['<start> really ? <end>', '<start> 你 确 定 ？ <end>'],\n",
       " ['<start> try it . <end>', '<start> 试 试 吧 。 <end>'],\n",
       " ['<start> we try . <end>', '<start> 我 们 来 试 试 。 <end>']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Remove the accents\n",
    "# 2. Clean the sentences\n",
    "# 3. Return word pairs in the format: [ENGLISH, CHINESE]\n",
    "def create_dataset(path, num_examples=None):\n",
    "    lines = open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "    word_pairs = [[w for w in l.split('\\t')] for l in lines[:num_examples]]\n",
    "    word_pairs = [[preprocess_eng(w[0]), preprocess_chinese(w[1])]\n",
    "                  for w in word_pairs]\n",
    "\n",
    "    # return two tuple: one tuple includes all English sentenses, and \n",
    "    # another tuple includes all Chinese sentenses\n",
    "    return word_pairs\n",
    "\n",
    "\n",
    "word_pairs = create_dataset(path_to_file)\n",
    "# show the first twenty examples\n",
    "word_pairs[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> if a person has not had a chance to acquire his target language by the time he s an adult , he s unlikely to be able to reach native speaker level in that language . <end>\n",
      "<start> 如 果 一 個 人 在 成 人 前 沒 有 機 會 習 得 目 標 語 言 ， 他 對 該 語 言 的 認 識 達 到 母 語 者 程 度 的 機 會 是 相 當 小 的 。 <end>\n",
      "Size: 20289\n"
     ]
    }
   ],
   "source": [
    "en, chn = zip(*create_dataset(path_to_file))\n",
    "print(en[-1])\n",
    "print(chn[-1])\n",
    "# show the size of the dataset\n",
    "assert len(en) == len(chn)\n",
    "print(\"Size:\", len(en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_length(tensor):\n",
    "    # padding the sentence to max_length\n",
    "    return max(len(t) for t in tensor)\n",
    "\n",
    "def tokenize(lang):\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        filters='')\n",
    "    # generate a dictionary, e.g. word -> index(of the dictionary)\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "    # output the vector sequences, e.g. [1, 7, 237, 3, 2]\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "\n",
    "    # padding sentences to the same length\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                           padding='post')\n",
    "    return tensor, lang_tokenizer\n",
    "\n",
    "def load_dataset(path, num_examples=None):\n",
    "    # creating cleaned input, output pairs\n",
    "    # regard Chinese as source sentence, regard English as target sentence\n",
    "    targ_lang, inp_lang = zip(*create_dataset(path, num_examples))\n",
    "\n",
    "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "\n",
    "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training data: 19274\n",
      "# test data: 1015\n"
     ]
    }
   ],
   "source": [
    "# Try experimenting with the size of that dataset\n",
    "# num_examples = 10000, if num examples = None means no limitation\n",
    "num_examples = None\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(\n",
    "    path_to_file, num_examples)\n",
    "\n",
    "# Calculate max_length of the target tensors\n",
    "max_length_targ, max_length_inp = max_length(\n",
    "    target_tensor), max_length(input_tensor)\n",
    "\n",
    "# Creating training and validation sets using an 95-5 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(\n",
    "    input_tensor, target_tensor, test_size=0.05)\n",
    "\n",
    "# Show length of the training data and validation data\n",
    "print(\"# training data: {:d}\\n# test data: {:d}\".format(len(input_tensor_train), len(input_tensor_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "1 ----> <start>\n",
      "4 ----> 我\n",
      "197 ----> 應\n",
      "144 ----> 該\n",
      "337 ----> 拿\n",
      "33 ----> 那\n",
      "96 ----> 些\n",
      "250 ----> 錢\n",
      "5 ----> 的\n",
      "3 ----> 。\n",
      "2 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "1 ----> <start>\n",
      "4 ----> i\n",
      "74 ----> should\n",
      "21 ----> have\n",
      "862 ----> taken\n",
      "5 ----> the\n",
      "125 ----> money\n",
      "3 ----> .\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "def convert(lang, tensor):\n",
    "    for t in tensor:\n",
    "        if t != 0:\n",
    "            print(\"%d ----> %s\" % (t, lang.index_word[t]))\n",
    "\n",
    "print(\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[0])\n",
    "print()\n",
    "print(\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a tf.data dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([128, 46]), TensorShape([128, 38]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 128\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "# 0 is a reserved index that won't be assigned to any word, so the size of vocabulary should add 1\n",
    "vocab_inp_size = len(inp_lang.word_index) + 1\n",
    "vocab_tar_size = len(targ_lang.word_index) + 1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        # vacab_size=vocab_inp_size=9394, embedding_dim=256 enc_units=1024 batch_sz=128\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_activation='sigmoid',\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        # x is the training data with shape == (batch_size, max_length)  -> (128, 46)\n",
    "        # which means there are batch_size sentences in one batch, the length of each sentence is max_length\n",
    "        # hidden state shape == (batch_size, units) -> (128, 1024)\n",
    "        # after embedding, x shape == (batch_size, max_length, embedding_dim) -> (128, 46, 256)\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # output contains the state(in GRU, the hidden state and the output are same) from all timestamps,\n",
    "        # output shape == (batch_size, max_length, units) -> (128, 46, 1024)\n",
    "        # state is the hidden state of the last timestamp, shape == (batch_size, units) -> (128, 1024)\n",
    "        output, state = self.gru(x, initial_state=hidden)\n",
    "        \n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        # initialize the first state of the gru,  shape == (batch_size, units) -> (128, 1024)\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (128, 46, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (128, 1024)\n",
      "tf.Tensor([ True  True  True ...  True  True  True], shape=(1024,), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))\n",
    "\n",
    "# the output and the hidden state of GRU is equal\n",
    "print(sample_output[-1, -1, :] == sample_hidden[-1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # query shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # we are doing this to perform addition to calculate the score\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = self.V(tf.nn.tanh(self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape == (batch_size, max_length, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        \n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (128, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (128, 46, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        # vocab_size=vocab_tar_size=6082, embedding_dim=256, dec_units=1024, batch_sz=128\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        # the dimension of the output is the vocab size, through the softmax function,\n",
    "        # this layer will return the probability of each word in the dictory\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        # used for attention\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        # This function outputs a result at each timestamp\n",
    "        # The hidden state of fisrt timestamp in the decoder is \n",
    "        # the hidden state of last timestamp in the encoder\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "        \n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # concatenate the input x and the context_vector, as the input of the GRU\n",
    "        # context_vector shape == (batch_size, units) -> (128, 1024)\n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size) -> (128, 1, 1024 + 256)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        # passing the concatenated vector to the GRU\n",
    "        # get the output and state of the current timestamp\n",
    "        # output shape == (batch_size, 1, units) -> (128, 1, 1024) \n",
    "        # state shape == (batch_size, units) -> (128, 1024)\n",
    "        output, state = self.gru(x)\n",
    "\n",
    "        # output shape == (batch_size, hidden_size) -> (128, 1024)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "        # output shape == (batch_size, vocab) -> (128, 6082)\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (128, 6082)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)), sample_hidden, sample_output)\n",
    "print('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the optimizer and the loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    \"\"\"Calculate the loss value\n",
    "    Args:\n",
    "        real: the true label  shape == (batch_size,) -> (128,)\n",
    "        pred: the probability of each word from the vocabulary, is the output from the decoder \n",
    "                 shape == (batch_size, vocab_size) -> (128, 6082)\n",
    "\n",
    "    Returns: \n",
    "        the average loss of the data in a batch size\n",
    "    \"\"\"\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoints (Object-based saving)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './checkpoints/chinese-eng'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "        dec_hidden = enc_hidden\n",
    "        \n",
    "        # feed the <start> as the first input of the decoder\n",
    "        # dec input shape == (batch_size, 1) -> (128, 1)\n",
    "        dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "        # Teacher forcing - feeding the target as the next input\n",
    "        # because of the data preprocessing(add a start token to the sentence)\n",
    "        # the first word is <start>, so t starts from 1(not 0)\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            # passing enc_output to the decoder\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "            # targ[:, t] is the true label(index of the word) of every sentence(in a batch) \n",
    "            # at the current timestamp\n",
    "            # like [  85   18   25   25  ···  1047   79   13], shape == (batch_size,) -> (128,)\n",
    "            # predictions shape == (batch_size, vocab_size) -> (128, 6082)\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "            # using teacher forcing\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "    # collect all trainable variables\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "    # calculate the gradients for the whole variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "\n",
    "    # apply the gradients on the variables\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the epochs for training\n",
    "EPOCHS = 50\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    # get the initial hidden state of gru\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                         batch,\n",
    "                                                         batch_loss.numpy()))\n",
    "\n",
    "    # saving (checkpoint) the model every 5 epochs\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "        \n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1, total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    \"\"\"Translate a sentence\n",
    "    Args:\n",
    "        sentence: the test sentence        \n",
    "    \"\"\"\n",
    "    \n",
    "    # max_length_targ 38, max_length_inp 64\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "    sentence = preprocess_chinese(sentence)\n",
    "\n",
    "    # convert each word to the index in the test sentence\n",
    "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                           maxlen=max_length_inp,\n",
    "                                                           padding='post')\n",
    "\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    # hidden shape == (1, 1024)\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    \n",
    "    # enc out shape == (1, max_length_inp, 1024) -> (1, 46, 1024)\n",
    "    # enc hidden shape == (1, 1024)\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
    "        \n",
    "        # storing the attention weigths to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        # get the index which has the highest probability\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "        #  convert the index to the word\n",
    "        result += targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "        # when the decoder predicts the end, stop prediction\n",
    "        if targ_lang.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "\n",
    "        # the predicted id is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention_plot\n",
    "\n",
    "\n",
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    # you need to change the fname based on your system, and the Chinese can be displayed in the plot\n",
    "    font = FontProperties(fname=r\"./dataset/TaipeiSansTCBeta-Regular.ttf\", size=14)\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    # set the x-tick/y-tick labels with list of string labels\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, fontproperties=font)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict, fontproperties=font)\n",
    "\n",
    "    # set tick locators\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    plt.show()\n",
    "\n",
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./checkpoints/chinese-eng\\ckpt-10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x18668f9ef10>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_dir = './checkpoints/chinese-eng'\n",
    "print(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> 你 今 晚 會 去 派 對 嗎 ? <end>\n",
      "Predicted translation: will you go to the party tonight ? <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate('你今晚會去派對嗎?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> 她 明 年 會 去 美 國 嗎 ? <end>\n",
      "Predicted translation: will she go to america next year ? <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate('她明年會去美國嗎?')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "22c6df8416d99150f2220dbf1611e4fb62265fefa3bde7b85f317bcaabf8ed29"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
